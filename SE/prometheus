安装即可
docker安装默认禁用--web.enable-lifecycle

被监控端需要安装exporter来提供数据
一般用node_exporter
node_exporter 无配置文件
node_exporter 开放端口后，直接启动即可。默认9100
指定端口和路径
node_exporter --web.listen-address=":9222"  --web.telemetry-path="/node_metrics"
添加主机之后需要更新Prometheus服务端配置文件

如果不想每次修改配置文件后都重启prometheus，可改用重载配置的方式。
重载配置需要在prometheus的启动参数中追加--web.enable-lifecycle
（如：./prometheus --web.enable-lifecycle）。
当修改配置文件（非服务发现的部分）后，执行curl -XPOST http://ip:port/-/reload
（其中，ip:port为相应节点的ip和prometheus服务监听的端口）。




检查配置文件：
./promtool check config prometheus.yml


prometheus.yml配置文件示例：

# my global config
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets:
       - 172.17.171.81:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  - "./rules/*.yml"
    #  - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:

#节点监控
  - job_name: 'node_monitor'
    static_configs:
      - targets:
        - wecode_db:9100
        - cloud_test:9100

    metric_relabel_configs:
    - source_labels: [version]
      separator: ','
      regex: '(version.*)'
      action:        drop
#web监控
  - job_name: 'http_status'
    metrics_path: /probe
    params:
      module: [http_2xx]
    static_configs:
      - targets:
        - https://cloud-channel.wecodetrace.com
        - https://reh5.wecodetrace.com

    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 172.17.171.81:9115
#端口监控
  - job_name: 'ports_status'
    scrape_interval: 5s
    metrics_path: /probe
    params:
      module: [tcp_connect]
    static_configs:
      - targets:
         - wecode_prod:80
           #- wecode_prod:8081
           #- wecode_prod:8082
           #- wecode_prod:8083
         - wecode_prod:8091

    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 172.17.171.81:9115
#主机监控
  - job_name: 'ping_status'
    scrape_interval: 5s
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets:
        - cell_prod
        - wecode_web_test

    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 172.17.171.81:9115

告警规则配置文件详解
groups:
- name: example
  rules:
  - alert: HighErrorRate
    expr: job:request_latency_seconds:mean5m{job="myjob"} > 0.5
    for: 10m
    labels:
      severity: page
    annotations:
      summary: High request latency
      description: description info


告警规则配置文件示例：
groups:
    - name: 节点状态-监控告警
      rules:
      - alert: 节点状态
        expr: up{job="node_monitor"} == 0
        for: 1m
        labels:
          status: 很是严重
        annotations:
          summary: "{{$labels.instance}}:节点不通"
          description: "{{$labels.instance}}:监控端服务异常，请及时查看"
      - alert: CPU使用状况
        expr: 100-(avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) by(instance)* 100) > 60
        for: 1m
        labels:
          status: 通常告警
        annotations:
          summary: "{{$labels.mountpoint}} CPU使用率太高！"
          description: "{{$labels.mountpoint }} CPU使用大于60%(目前使用:{{$value}}%)"
      - alert: 内存使用
        expr: (node_memory_MemTotal_bytes - node_memory_MemFree_bytes - node_memory_Buffers_bytes - node_memory_Cached_bytes) / node_memory_MemTotal_bytes * 100> 90
        for: 1m
        labels:
          status: 严重告警
        annotations:
          summary: "{{$labels.mountpoint}} 内存使用率太高！"
          description: "{{$labels.mountpoint }} 内存使用大于90%(目前使用:{{$value}}%)"
      - alert: IO性能
        expr: 100-(avg(irate(node_disk_io_time_seconds_total[1m])) by(instance)* 100) < 60
        for: 1m
        labels:
          status: 严重告警
        annotations:
          summary: "{{$labels.mountpoint}} 流入磁盘IO使用率太高！"
          description: "{{$labels.mountpoint }} 流入磁盘IO大于60%(目前使用:{{$value}})"
      - alert: 网络
        expr: ((sum(rate (node_network_receive_bytes_total{device!~'tap.*|veth.*|br.*|docker.*|virbr*|lo*'}[5m])) by (instance)) / 100) > 102400
        for: 1m
        labels:
          status: 严重告警
        annotations:
          summary: "{{$labels.mountpoint}} 流入网络带宽太高！"
          description: "{{$labels.mountpoint }}流入网络带宽持续2分钟高于100M. RX带宽使用率{{$value}}"
      - alert: 网络
        expr: ((sum(rate (node_network_transmit_bytes_total{device!~'tap.*|veth.*|br.*|docker.*|virbr*|lo*'}[5m])) by (instance)) / 100) > 102400
        for: 1m
        labels:
          status: 严重告警
        annotations:
          summary: "{{$labels.mountpoint}} 流出网络带宽太高！"
          description: "{{$labels.mountpoint }}流出网络带宽持续2分钟高于100M. RX带宽使用率{{$value}}"
      - alert: TCP会话
        expr: node_netstat_Tcp_CurrEstab > 1000
        for: 1m
        labels:
          status: 严重告警
        annotations:
          summary: "{{$labels.mountpoint}} TCP_ESTABLISHED太高！"
          description: "{{$labels.mountpoint }} TCP_ESTABLISHED大于1000%(目前使用:{{$value}}%)"
      - alert: 磁盘容量
        expr: 100-(node_filesystem_free_bytes{fstype=~"ext4|xfs"}/node_filesystem_size_bytes {fstype=~"ext4|xfs"}*100) > 80
        for: 1m
        labels:
          status: 严重告警
        annotations:
          summary: "{{$labels.mountpoint}} 磁盘分区使用率太高！"
          description: "{{$labels.mountpoint }} 磁盘分区使用大于80%(目前使用:{{$value}}%)"



alert：告警规则的名称。
expr：基于PromQL表达式告警触发条件，用于计算是否有时间序列满足该条件。
for：评估等待时间，可选参数。用于表示只有当触发条件持续一段时间后才发送告警。在等待期间新产生告警的状态为pending。
labels：自定义标签，允许用户指定要附加到告警上的一组附加标签。
annotations：用于指定一组附加信息，比如用于描述告警详细信息的文字等，annotations的内容在告警产生时会一同作为参数发送到Alertmanager。


在Alertmanager中通过路由(Route)来定义告警的处理方式。路由是一个基于标签匹配的树状匹配结构。根据接收到告警的标签匹配相应的处理方式。这里将详细介绍路由相关的内容。

Alertmanager主要负责对Prometheus产生的告警进行统一处理
Alertmanager配置中主要部分：

全局配置（global）：用于定义一些全局的公共参数，如全局的SMTP配置，Slack配置等内容；
模板（templates）：用于定义告警通知时的模板，如HTML模板，邮件模板等；
告警路由（route）：根据标签匹配，确定当前告警应该如何处理；
接收人（receivers）：接收人是一个抽象的概念，它可以是一个邮箱也可以是微信，Slack或者Webhook等，接收人一般配合告警路由使用；
抑制规则（inhibit_rules）：合理设置抑制规则可以减少垃圾告警的产生

其完整配置格式如下：

global:
  [ resolve_timeout: <duration> | default = 5m ]
  [ smtp_from: <tmpl_string> ]
  [ smtp_smarthost: <string> ]
  [ smtp_hello: <string> | default = "localhost" ]
  [ smtp_auth_username: <string> ]
  [ smtp_auth_password: <secret> ]
  [ smtp_auth_identity: <string> ]
  [ smtp_auth_secret: <secret> ]
  [ smtp_require_tls: <bool> | default = true ]
  [ slack_api_url: <secret> ]
  [ victorops_api_key: <secret> ]
  [ victorops_api_url: <string> | default = "https://alert.victorops.com/integrations/generic/20131114/alert/" ]
  [ pagerduty_url: <string> | default = "https://events.pagerduty.com/v2/enqueue" ]
  [ opsgenie_api_key: <secret> ]
  [ opsgenie_api_url: <string> | default = "https://api.opsgenie.com/" ]
  [ hipchat_api_url: <string> | default = "https://api.hipchat.com/" ]
  [ hipchat_auth_token: <secret> ]
  [ wechat_api_url: <string> | default = "https://qyapi.weixin.qq.com/cgi-bin/" ]
  [ wechat_api_secret: <secret> ]
  [ wechat_api_corp_id: <string> ]
  [ http_config: <http_config> ]

templates:
  [ - <filepath> ... ]

route: <route>

receivers:
  - <receiver> ...

inhibit_rules:
  [ - <inhibit_rule> ... ]

在全局配置中需要注意的是resolve_timeout，该参数定义了当Alertmanager持续多长时间未接收到告警后标记告警状态为resolved（已解决）。
该参数的定义可能会影响到告警恢复通知的接收时间，读者可根据自己的实际场景进行定义，其默认值为5分钟。

检查配置：
./amtool check-config alertmanager.yml

alertmanager.yml配置文件示例

global:
  resolve_timeout: 1m
  smtp_smarthost: 'smtp.exmail.qq.com:465'
  smtp_from: 'lifeng@tprut.com'              #发件人邮箱
  smtp_auth_username: 'lifeng@tprut.com'    #发件人用户名
  smtp_auth_password: '79Cu7eLF8MRFVQjR'    #邮箱授权码(这个码要登录你的邮箱在设置里可以获取)
  smtp_require_tls: false
templates:
   - 'templates/email.tmpl'
route:
  group_by: ['monitor']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'email'
receivers:
- name: 'email'
  email_configs:
  - to: 'lifeng@tprut.com'                #收件人邮箱
    headers: {Subject: "WARNING-告警邮件"}
    html: '{{ template "email.to.html" . }}'
    send_resolved: true
inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'dev', 'instance']


global: # 全局配置
  resolve_timeout: 5m # 超时时间 默认5m
inhibit_rules:
  - source_match:      ## 源报警规则
      severity: 90
    target_match:      ## 抑制的报警规则
      severity: 80
    equal: [kafka,instance]    ## 需要都有相同的标签及值，否则抑制不起作用
route:
  receiver: webhook1
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  group_by: [demo, kafka, instance] # 对应prometheus  rules规则文件中的team
  routes:
  - receiver: webhook2 # 对应下面
    group_by: [nodeExt2]
    matchers:
    - team = kafka
    group_interval: 10s
    group_wait: 30s
    repeat_interval: 60m
  - receiver: webhook3
    group_by: [nodeExt3]
    matchers:
    - team = instance
    group_interval: 10s
    group_wait: 30s
    repeat_interval: 60m
receivers:
- name: webhook1
  webhook_configs: # webhook告警配置
  - url: http://172.16.1.165:29098/maintenanceApi/order/alarm
- name: webhook2
  webhook_configs: # webhook告警配置
  - url: http://172.16.1.165:29098/maintenanceApi/order/alarm2
- name: webhook3
  webhook_configs: # webhook告警配置
  - url: http://172.16.1.165:29098/maintenanceApi/order/alarm3



email.tmpl配置文件示例

{{ define "email.to.html" }}
{{- if gt (len .Alerts.Firing) 0 -}}
{{ range .Alerts }}
<pre>




    =============监控告警===========
    告警程序： prometheus_alertmanager

    告警类型： {{ .Labels.alertname }}
    故障主机： {{ .Labels.instance }}
    告警主题： {{ .Annotations.summary }}
    告警详情： {{ .Annotations.description }}
    触发时间： {{ .StartsAt.Local.Format "2006-01-02 15:04:23" }}
    ==============end============



</pre>
{{ end }}
{{ end }}

{{- if gt (len .Alerts.Resolved) 0 -}}
{{ range .Alerts }}
<pre>




    =============告警恢复===========
    告警程序： prometheus_alertmanager

    告警类型： {{ .Labels.alertname }}
    故障主机： {{ .Labels.instance }}
    告警主题： {{ .Annotations.summary }}
    告警详情： {{ .Annotations.description }}
    触发时间： {{ .StartsAt.Local.Format "2006-01-02 15:04:23" }}
    恢复时间： {{ .EndsAt.Local.Format "2006-01-02 15:04:23" }}
    ==============end============



</pre>
{{ end }}
{{ end }}
{{ end }}

热重启
curl -XPOST http://localhost:9093/-/reload

blackbox_exporter  用于监控web状态码、ssl证书时效、端口是否开放、ping等数据
blackbox_exporter配置文件示例
